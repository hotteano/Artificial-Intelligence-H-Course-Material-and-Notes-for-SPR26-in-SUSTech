# ğŸ¤– Artificial Intelligence (H) Notes

---

## ğŸ“š Table of Contents

1. [An Introduction to AI](#-an-introduction-to-ai)
2. [Agents](#-agents)
3. [Search Algorithms](#-search-algorithms)
   - [Uninformed Search](#-uninformed-search)
   - [Informed Search](#-informed-search)
   - [Local Search](#-local-search)
   - [Adversarial Search](#-adversarial-search)

---

## ğŸŒŸ An Introduction to AI

### ğŸ’¡ What is Artificial Intelligence?

> **å®šä¹‰** | Artificial Intelligence (AI) is not formally defined, but it generally refers to the simulation of human intelligence in machines that are programmed to think and learn like humans.

AI can be categorized into two main types:

| Type | Description | Examples |
|:----:|:------------|:---------|
| ğŸ¯ **Narrow AI** | Designed for specific tasks | Siri, AlphaGo, Recommendation systems |
| ğŸŒ **General AI** | Can perform any intellectual task that a human can do | *Still theoretical* |

---

### ğŸ“œ History of AI

```
Timeline of AI Development
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1956 ğŸ“  â”‚ Dartmouth Conference: "AI" coined
1960s-70s â”‚ ELIZA, SHRDLU
1980s    â”‚ ğŸ“ˆ Expert Systems boom
1990s    â”‚ ğŸ¤– Machine Learning + Big Data
2000s    â”‚ ğŸ§  Deep Learning revolution
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

> **Key Milestones**:
> - ğŸ›ï¸ **1956**: The term "Artificial Intelligence" was coined at the Dartmouth Conference
> - ğŸ’¬ **1960s-1970s**: Early AI programs (ELIZA, SHRDLU)
> - ğŸ‘” **1980s**: Rise of expert systems
> - ğŸ“Š **1990s**: Machine learning algorithms + Big data
> - ğŸ§  **2000s**: Deep learning and neural networks breakthrough

---

## ğŸ”§ Agents

### ğŸ­ What is an Agent?

> **å®šä¹‰** | An **agent** is an entity that perceives its environment through **sensors** and acts upon that environment through **actuators**.

Agents can be:
- ğŸ”¹ **Simple**: Thermostat
- ğŸ”¹ **Complex**: Self-driving car, Robot assistant

---

### ğŸ—ï¸ Agent Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ğŸ¯ AGENT                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ ğŸ“¥ Sensors  â”‚â—„â”€â”€â”€â”‚ ğŸŒ Environmentâ”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                               â”‚
â”‚         â–¼                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚  ğŸ§  Percept     â”‚                    â”‚
â”‚  â”‚  âš™ï¸ Decision    â”‚                    â”‚
â”‚  â”‚  ğŸ¬ Action      â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚           â”‚                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚ ğŸ“¤ Actuators    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Search Algorithms

---

### ğŸ”µ Uninformed Search

> ğŸ“Œ **Uninformed Search** (also known as **Blind Search**) refers to search strategies that have no additional information about states beyond that provided in the problem definition.

#### ğŸ“Š Complexity Comparison

| Algorithm | Complete? | Optimal? | â±ï¸ Time | ğŸ’¾ Space |
|:---------:|:---------:|:--------:|:-------:|:--------:|
| **BFS** | âœ… Yes | âœ… Yes (if cost=1) | $O(b^d)$ | $O(b^d)$ |
| **UCS** | âœ… Yes | âœ… Yes | $O(b^{1+\lfloor C^*/\epsilon \rfloor})$ | $O(b^{1+\lfloor C^*/\epsilon \rfloor})$ |
| **DFS** | âŒ No | âŒ No | $O(b^m)$ | $O(bm)$ |
| **DLS** | âŒ No | âŒ No | $O(b^\ell)$ | $O(b\ell)$ |
| **IDS** | âœ… Yes | âœ… Yes (if cost=1) | $O(b^d)$ | $O(bd)$ |
| **BDS** | âœ… Yes | âœ… Yes | $O(b^{d/2})$ | $O(b^{d/2})$ |

> ğŸ“ **Notation**: $b$ = branching factor, $d$ = depth of shallowest solution, $m$ = maximum depth, $\ell$ = depth limit, $C^*$ = cost of optimal solution

---

#### ğŸŒŠ Breadth-First Search (BFS)

> ğŸ’¡ Expands the **shallowest** unexpanded node first using a **FIFO queue**.

```python
function BFS(problem):
    node â† Node(problem.INITIAL_STATE)
    if problem.IS_GOAL(node.state) then return node
    frontier â† FIFO queue with node
    reached â† {problem.INITIAL_STATE}
    
    while frontier is not empty:
        node â† POP(frontier)
        for child in EXPAND(problem, node):
            s â† child.state
            if problem.IS_GOAL(s) then return child
            if s not in reached then:
                add s to reached
                add child to frontier
    return failure
```

> âœ… **Properties**: Complete if $b$ is finite; Optimal if step costs are equal; High space complexity is the main drawback.

---

#### âš–ï¸ Uniform Cost Search (UCS)

> ğŸ’¡ Expands the node with the **lowest path cost** $g(n)$ using a **priority queue**.

- ğŸ”„ Equivalent to Dijkstra's algorithm
- ğŸ¯ Always finds the least-cost path
- ğŸ“ˆ Explores nodes in order of increasing path cost

---

#### ğŸ”½ Depth-First Search (DFS)

> ğŸ’¡ Expands the **deepest** unexpanded node first using a **LIFO stack**.

```python
function DFS(problem):
    return RECURSIVE_DFS(problem, Node(problem.INITIAL_STATE))

function RECURSIVE_DFS(problem, node):
    if problem.IS_GOAL(node.state) then return node
    for child in EXPAND(problem, node):
        result â† RECURSIVE_DFS(problem, child)
        if result â‰  failure then return result
    return failure
```

> âš ï¸ **Properties**: Not complete (may loop infinitely); Not optimal; Linear space complexity $O(bm)$ is the main advantage.

---

#### ğŸ”¢ Depth-Limited Search (DLS)

> ğŸ’¡ DFS with a predetermined **depth limit** $\ell$ to avoid infinite paths.

---

#### ğŸ”„ Iterative Deepening Search (IDS)

> ğŸ’¡ Performs DLS with increasing depth limits: `0, 1, 2, 3, ...`

| âœ… Advantages | âš ï¸ Considerations |
|:-------------|:------------------|
| Combines BFS completeness + DFS low space | Overhead of regenerated nodes |
| Preferred for large state spaces | Usually small overhead in practice |

---

#### â†”ï¸ Bidirectional Search

> ğŸ’¡ Runs two simultaneous searches: forward from initial state and backward from goal.

- ğŸ›‘ Stops when the two searches meet
- ğŸš€ Reduces time and space to $O(b^{d/2})$
- âš ï¸ Requires ability to compute predecessors

---

### ğŸŸ¢ Informed Search

> ğŸ“Œ **Informed Search** (also known as **Heuristic Search**) uses problem-specific knowledge to find solutions more efficiently via a **heuristic function** $h(n)$.

#### ğŸ“Š Algorithm Comparison

| Algorithm | Complete? | Optimal? | â±ï¸ Time | ğŸ’¾ Space |
|:---------:|:---------:|:--------:|:-------:|:--------:|
| **Greedy Best-First** | âŒ No | âŒ No | $O(b^m)$ | $O(b^m)$ |
| **A\*** | âœ… Yes | âœ… Yes | Exponential | Exponential |
| **IDA\*** | âœ… Yes | âœ… Yes | Exponential | $O(bd)$ |
| **RBFS** | âœ… Yes | âœ… Yes | Exponential | $O(bd)$ |
| **SMA\*** | âœ… Yes | âœ… Yes | Exponential | Limited |

---

#### ğŸ¯ Heuristic Function Properties

> ğŸ“ **Admissible**: $h(n) \leq h^*(n)$ for all $n$
> - âœ… Never overestimates the cost to reach the goal
> - ğŸ”‘ Required for A* optimality

> ğŸ“ **Consistent (Monotonic)**: $h(n) \leq c(n, a, n') + h(n')$
> - ğŸ”º Triangle inequality: estimated cost never decreases faster than actual step cost
> - âœ… Every consistent heuristic is admissible

---

#### ğŸƒ Greedy Best-First Search

> ğŸ’¡ Expands the node that **appears closest** to the goal according to $h(n)$.

- ğŸ“Š Evaluation: $f(n) = h(n)$
- ğŸ† Greedy approach: minimize estimated cost to goal
- âŒ Not complete and not optimal
- ğŸ”„ Can get stuck in loops

---

#### â­ A* Search

> ğŸ’¡ Expands the node with the lowest **combined cost**: $f(n) = g(n) + h(n)$

| Component | Meaning |
|:----------|:--------|
| $g(n)$ | ğŸ“ Actual cost from **start** to $n$ |
| $h(n)$ | ğŸ¯ Estimated cost from $n$ to **goal** |
| $f(n)$ | ğŸ’° Estimated **total cost** of cheapest solution through $n$ |

> ğŸ† **Optimality**: A* is optimal if $h(n)$ is **admissible** (tree search) or **consistent** (graph search).

```python
function A_STAR(problem):
    node â† Node(problem.INITIAL_STATE)
    frontier â† priority queue ordered by f = g + h, with node
    reached â† {problem.INITIAL_STATE: node}
    
    while frontier is not empty:
        node â† POP(frontier)
        if problem.IS_GOAL(node.state) then return node
        for child in EXPAND(problem, node):
            s â† child.state
            if s not in reached or child.path_cost < reached[s].path_cost:
                reached[s] â† child
                add child to frontier
    return failure
```

---

#### ğŸ”„ Iterative Deepening A* (IDA*)

> ğŸ’¡ Combines iterative deepening with A* evaluation.

- ğŸ“ Uses $f$-cost limit instead of depth limit
- ğŸ“Š Threshold is the smallest $f$-cost that exceeded the previous threshold
- ğŸ’¾ Memory-efficient: $O(bd)$ space
- ğŸ® Suitable for problems with large state spaces

---

#### ğŸŒ² Recursive Best-First Search (RBFS)

> ğŸ’¡ Recursive algorithm that mimics best-first search with **linear space**.

- ğŸ“ Keeps track of the best alternative path available
- â†©ï¸ Backtracks when current path exceeds this alternative
- ğŸ’¾ Memory efficient but may re-expand nodes

---

#### ğŸ’¾ Simplified Memory-Bounded A* (SMA*)

> ğŸ’¡ A* with **memory limit**; when memory is full, drops the worst node.

- âœ‚ï¸ Prunes nodes with highest $f$-cost
- ğŸ§  Remembers best descendant's cost in parent
- âœ… Complete if any solution fits in memory
- ğŸ† Optimal if optimal solution fits in memory

---

### ğŸŸ¡ Local Search

> ğŸ“Œ **Local Search** algorithms operate by searching from a current state to neighboring states, without keeping track of paths. Suitable for **optimization problems**.

#### âœ¨ Characteristics

| Feature | Description |
|:--------|:------------|
| ğŸ’¾ Space | Constant $O(1)$ â€” only keep current state |
| ğŸ—ºï¸ State Space | Large or infinite spaces |
| ğŸ¯ Goal | Find best state by **objective function** |
| âš ï¸ Trade-off | Not systematic â€” may miss optimal solutions |

#### ğŸ“Š Algorithm Comparison

| Algorithm | Complete? | Optimal? | ğŸ”„ Escape Local Optima? |
|:---------:|:---------:|:--------:|:-----------------------:|
| **Hill Climbing** | âŒ No | âŒ No | âŒ No |
| **Random Restart HC** | âœ… Yes (prob.) | âŒ No | ğŸ”„ Restart-based |
| **Simulated Annealing** | âœ… Yes (prob.) | âœ… Yes (prob.) | âœ… Yes |
| **Local Beam Search** | âŒ No | âŒ No | ğŸ‘¥ Parallel exploration |
| **Genetic Algorithm** | âŒ No | âŒ No | ğŸ§¬ Crossover/Mutation |

---

#### ğŸ”ï¸ State Space Landscape

```
        ğŸ”ï¸ Global Max
           /\\
          /  \\
         /    \\      ğŸ”ï¸ Local Max
   _____/      \\____    /\\
  /              \\  \\  /  \\
 /                \\--\\/    \\____
/       ğŸ”ï¸ Local Max             \\____
```

| Terrain Feature | Description |
|:----------------|:------------|
| ğŸ”ï¸ **Global Maximum** | Best possible state |
| ğŸ”ï¸ **Local Maximum** | Better than neighbors, but not the best |
| ğŸ“ **Plateau** | Flat area where neighbors have equal value |
| ğŸ”ï¸ **Ridge** | Sequence of local maxima, difficult to navigate |

---

#### ğŸ§— Hill Climbing (Steepest-Ascent)

> ğŸ’¡ Greedy local search that always moves to the **best neighboring state**.

```python
function HILL_CLIMBING(problem):
    current â† problem.INITIAL_STATE
    while True:
        neighbor â† highest-valued successor of current
        if VALUE(neighbor) â‰¤ VALUE(current) then return current
        current â† neighbor
```

**Variants**:
- ğŸ² **Stochastic HC**: chooses randomly among uphill moves
- â© **First-Choice HC**: generates successors randomly, picks first improvement
- ğŸ”„ **Random-Restart HC**: multiple searches from random initial states

**Problems** âš ï¸:
- ğŸ”ï¸ **Local maxima**: stuck at peaks that aren't the global maximum
- ğŸ“ **Ridges**: cause slow progress or getting stuck
- ğŸ“ **Plateaus**: flat areas with no uphill direction

---

#### ğŸŒ¡ï¸ Simulated Annealing

> ğŸ’¡ Combines hill climbing with **random walk** to escape local maxima.

> ğŸ”¬ Inspired by **metallurgical annealing**: heat metal then cool slowly to reach low-energy crystalline state.

```python
function SIMULATED_ANNEALING(problem, schedule):
    current â† problem.INITIAL_STATE
    for t = 1 to âˆ:
        T â† schedule(t)                    # ğŸŒ¡ï¸ temperature
        if T = 0 then return current
        next â† randomly selected successor of current
        Î”E â† VALUE(next) - VALUE(current)
        if Î”E > 0 then current â† next      # â¬†ï¸ uphill: always accept
        else current â† next with probability e^(Î”E/T)  # â¬‡ï¸ downhill: probabilistic
```

| Phase | Behavior |
|:------|:---------|
| ğŸ”¥ **Early** (High T) | More random exploration |
| â„ï¸ **Late** (Low T) | Greedy hill climbing |
| ğŸ¯ **Theory** | With slow enough cooling, probability of optimal solution â†’ 1 |

---

#### ğŸ‘¥ Local Beam Search

> ğŸ’¡ Keeps track of **$k$ states** instead of just one.

```python
function LOCAL_BEAM_SEARCH(problem, k):
    states â† k randomly generated states
    while True:
        successors â† []
        for each state in states:
            successors â† successors âˆª ALL_SUCCESSORS(state)
        states â† k best successors
        if all states have same value then return best(states)
```

- ğŸ’¬ Information is shared among parallel searches
- ğŸš€ If one search finds a good path, others follow
- âš ï¸ Can suffer from **lack of diversity** (all states cluster)
- ğŸ² **Stochastic Beam Search**: chooses $k$ successors probabilistically

---

#### ğŸ§¬ Genetic Algorithms (GA)

> ğŸ’¡ Population-based search inspired by **biological evolution**.

```python
function GENETIC_ALGORITHM(population, fitness_fn):
    repeat:
        new_population â† empty set
        for i = 1 to SIZE(population):
            x â† RANDOM_SELECTION(population, fitness_fn)
            y â† RANDOM_SELECTION(population, fitness_fn)
            child â† REPRODUCE(x, y)
            if small random probability then child â† MUTATE(child)
            add child to new_population
        population â† new_population
    until some individual is fit enough or time expired
    return best individual

function REPRODUCE(x, y):
    n â† LENGTH(x)
    c â† random number from 1 to n
    return APPEND(SUBSTRING(x, 1, c), SUBSTRING(y, c+1, n))
```

**Key Operations** ğŸ”‘:
- ğŸ¯ **Selection**: probabilistically choose parents based on fitness
- ğŸ”„ **Crossover**: combine two parents to create offspring
- ğŸ² **Mutation**: random alteration with small probability

**State Representation**: Usually encoded as strings (binary, real-valued, etc.)

**Applications** ğŸ¯: Function optimization, scheduling, design problems, neural network training

---

#### ğŸ“Š Comparison Summary

| Aspect | Systematic Search | Local Search |
|:-------|:-----------------|:-------------|
| ğŸ’¾ Memory | High ($O(b^d)$) | Low ($O(1)$) |
| âœ… Complete | Often yes | Usually no |
| ğŸ† Optimal | Often yes | Usually no |
| ğŸ¯ Best for | Finding paths | Optimization |
| ğŸ—ºï¸ State space | Any | Large or continuous |

---

### ğŸ”´ Adversarial Search

> ğŸ“Œ **Adversarial Search** deals with **multi-agent environments** where agents have conflicting goals (competitive games). The agent must consider the opponent's actions, assuming optimal play.

#### ğŸ® Key Characteristics

| Property | Description |
|:---------|:------------|
| âš–ï¸ **Zero-sum games** | One player's gain is another's loss |
| ğŸ‘ï¸ **Perfect information** | All players know complete game state (e.g., chess) |
| ğŸ¯ **Deterministic** | No random elements in state transitions |
| ğŸ”„ **Turn-taking** | Players alternate moves |

#### ğŸ² Game Formulation

| Component | Description |
|:----------|:------------|
| ğŸš€ **Initial State** | Starting position and player to move |
| ğŸ“‹ **Actions(s)** | Legal moves in state $s$ |
| ğŸ”„ **Result(s, a)** | Transition model |
| ğŸ **Terminal-Test(s)** | Is the game over? |
| ğŸ’¯ **Utility(s, p)** | Final value for player $p$ in terminal state $s$ |

---

#### âš«âšª Minimax Algorithm

> ğŸ’¡ Assumes the opponent plays optimally to **minimize** our utility.

```python
function MINIMAX_DECISION(state):
    return argmax_{a âˆˆ ACTIONS(state)} MIN_VALUE(RESULT(state, a))

function MAX_VALUE(state):
    if TERMINAL_TEST(state) then return UTILITY(state)
    v â† -âˆ
    for each a in ACTIONS(state):
        v â† MAX(v, MIN_VALUE(RESULT(state, a)))
    return v

function MIN_VALUE(state):
    if TERMINAL_TEST(state) then return UTILITY(state)
    v â† +âˆ
    for each a in ACTIONS(state):
        v â† MIN(v, MAX_VALUE(RESULT(state, a)))
    return v
```

| Property | Value |
|:---------|:------|
| âœ… **Complete** | Yes (if game tree is finite) |
| ğŸ† **Optimal** | Yes (against optimal opponent) |
| â±ï¸ **Time** | $O(b^m)$ â€” exponential in depth |
| ğŸ’¾ **Space** | $O(bm)$ â€” depth-first exploration |

> ğŸ“ **Notation**: $b$ = branching factor, $m$ = maximum depth

---

#### âœ‚ï¸ Alpha-Beta Pruning

> ğŸ’¡ Optimization of Minimax that **prunes branches** that cannot influence the final decision.

| Parameter | Meaning |
|:----------|:--------|
| **Î± (alpha)** | Best value that **MAX** can guarantee at current path |
| **Î² (beta)** | Best value that **MIN** can guarantee at current path |

```python
function ALPHA_BETA_SEARCH(state):
    return argmax_{a} MIN_VALUE(RESULT(state, a), -âˆ, +âˆ)

function MAX_VALUE(state, Î±, Î²):
    if TERMINAL_TEST(state) then return UTILITY(state)
    v â† -âˆ
    for each a in ACTIONS(state):
        v â† MAX(v, MIN_VALUE(RESULT(state, a), Î±, Î²))
        if v â‰¥ Î² then return v          # âœ‚ï¸ Î² cutoff
        Î± â† MAX(Î±, v)
    return v

function MIN_VALUE(state, Î±, Î²):
    if TERMINAL_TEST(state) then return UTILITY(state)
    v â† +âˆ
    for each a in ACTIONS(state):
        v â† MIN(v, MAX_VALUE(RESULT(state, a), Î±, Î²))
        if v â‰¤ Î± then return v          # âœ‚ï¸ Î± cutoff
        Î² â† MIN(Î², v)
    return v
```

| Case | Complexity |
|:-----|:-----------|
| ğŸ† **Best-case** | $O(b^{m/2})$ â€” with perfect move ordering |
| ğŸ“Š **Average-case** | $O(b^{3m/4})$ |
| ğŸ’¾ **Space** | $O(bm)$ â€” same as Minimax |

> ğŸ¯ **Move Ordering Heuristics**:
> - âš”ï¸ Try captures before quiet moves
> - ğŸ“ˆ Try moves with good historical scores
> - ğŸ—¡ï¸ Killer heuristic: moves that caused cutoffs before

---

#### â±ï¸ Cutting Off Search & Evaluation Functions

For most games, exploring to terminal states is **impossible** (chess has ~$10^{40}$ nodes).

> ğŸ’¡ **Approach**: Cut off search early and apply **evaluation function**:

```python
function CUTOFF_TEST(state, depth):
    return depth > limit or TERMINAL_TEST(state)

function EVAL(state):
    return estimated utility of state
```

**Evaluation Function Design** ğŸ“:
- ğŸ”¹ **Features**: Material, position, mobility, king safety, etc.
- ğŸ“Š **Weighted linear**: $\text{Eval}(s) = w_1f_1(s) + w_2f_2(s) + ... + w_nf_n(s)$
- âœ… Must preserve **transitivity**: if $A > B$, then $\text{Eval}(A) > \text{Eval}(B)$

> ğŸŒŠ **Quiescence Search**: Extend search in "unquiet" positions (e.g., captures) to avoid horizon effect.

---

#### ğŸ² Expectimax (Stochastic Games)

> ğŸ’¡ For games with **chance elements** (dice rolls, card draws).

Add **chance nodes** to the game tree:

```python
function EXPECTIMAX_DECISION(state):
    return argmax_{a} EXPECT_VALUE(RESULT(state, a))

function MAX_VALUE(state):
    if TERMINAL_TEST(state) then return UTILITY(state)
    v â† -âˆ
    for each a in ACTIONS(state):
        v â† MAX(v, EXPECT_VALUE(RESULT(state, a)))
    return v

function EXPECT_VALUE(state):
    if TERMINAL_TEST(state) then return UTILITY(state)
    v â† 0
    for each outcome with probability p:
        v â† v + p Ã— MAX_VALUE(RESULT(state, outcome))
    return v
```

| Feature | Description |
|:--------|:------------|
| ğŸ“Š **Expected value** | Calculation weighted by probabilities |
| ğŸ® **Applications** | Backgammon, poker, etc. |
| âœ‚ï¸ **Pruning** | Can combine with alpha-beta (expectiminimax) |

---

#### ğŸŒ³ Monte Carlo Tree Search (MCTS)

> ğŸ’¡ Widely used in modern game AI (**AlphaGo**, **Leela Chess**).

Four steps repeated iteratively:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ğŸ”„ MCTS Loop                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  1ï¸âƒ£  SELECTION                              â”‚
â”‚      Select child using UCB1 formula        â”‚
â”‚      UCB1 = (wins/visits) + C Ã— âˆš(ln(parent_visits)/visits) â”‚
â”‚                                             â”‚
â”‚  2ï¸âƒ£  EXPANSION                              â”‚
â”‚      Expand one child of the selected node  â”‚
â”‚                                             â”‚
â”‚  3ï¸âƒ£  SIMULATION                             â”‚
â”‚      Play random rollout from new node      â”‚
â”‚                                             â”‚
â”‚  4ï¸âƒ£  BACKPROPAGATION                        â”‚
â”‚      Update statistics up the tree          â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> ğŸ“Š **Upper Confidence Bound (UCB1)**: Balances exploitation (high win rate) vs exploration (few visits).

**Advantages** âœ…:
- ğŸ² No domain knowledge required (pure simulation)
- â±ï¸ **Anytime algorithm**: can stop at any point
- ğŸŒ³ Handles large branching factors well
- ğŸ”„ Parallelizable

---

#### ğŸ“Š Summary Table

| Algorithm | Perfect Info | Deterministic | Optimal | Complexity |
|:---------:|:------------:|:-------------:|:-------:|:----------:|
| **Minimax** | âœ… Yes | âœ… Yes | âœ… Yes | $O(b^m)$ |
| **Alpha-Beta** | âœ… Yes | âœ… Yes | âœ… Yes | $O(b^{m/2})$ |
| **Expectimax** | âœ… Yes | âŒ No | âœ… Yes | $O(b^m)$ |
| **MCTS** | âœ…/âŒ | Both | âŒ No | Polynomial |

---

#### ğŸŒ Applications Beyond Games

| Domain | Application |
|:-------|:------------|
| ğŸ’° **Auction design** | Bidding strategies |
| ğŸ”’ **Network security** | Attacker-defender models |
| ğŸ“ˆ **Economic modeling** | Competitive markets |
| ğŸ–ï¸ **Military planning** | Adversarial scenarios |
| ğŸ¤– **Robotics** | Multi-agent coordination/competition |

## ğŸ§® Mathematical Logic & Knowledge Representation

> ğŸ“Œ **Mathematical Logic** provides a formal foundation for representing knowledge and reasoning. It enables AI agents to draw valid conclusions from known facts.

---

### ğŸ§© Knowledge-Based Agents

> ğŸ’¡ A **knowledge-based agent** maintains a **knowledge base (KB)** and uses **inference** to derive new information.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ğŸ§  Knowledge-Based Agent               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ ğŸ“š Knowledge    â”‚â—„â”€â”€â”€â”€â–ºâ”‚   âš™ï¸ Inference      â”‚     â”‚
â”‚   â”‚    Base (KB)    â”‚      â”‚     Engine          â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚            â–²                        â”‚                   â”‚
â”‚            â”‚                        â–¼                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ ğŸŒ Percepts     â”‚      â”‚   ğŸ¯ Actions        â”‚     â”‚
â”‚   â”‚   (Tell)        â”‚      â”‚   (Ask/Execute)     â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Core Operations** ğŸ”‘:
- **TELL**: Add new facts to KB
- **ASK**: Query KB to derive conclusions

---

### ğŸ“ Propositional Logic (å‘½é¢˜é€»è¾‘)

> ğŸ’¡ **Propositional Logic** deals with propositions that are either **true** or **false**.

#### ğŸ”¹ Syntax & Semantics

| Connective | Symbol | Meaning | Truth Table |
|:----------:|:------:|:--------|:-----------:|
| Negation | Â¬ | NOT | Â¬P is true when P is false |
| Conjunction | âˆ§ | AND | P âˆ§ Q is true when both are true |
| Disjunction | âˆ¨ | OR | P âˆ¨ Q is true when at least one is true |
| Implication | â†’ | IF...THEN | P â†’ Q is false only when P=true, Q=false |
| Biconditional | â†” | IFF | P â†” Q is true when P and Q have same value |

#### ğŸ”¹ Important Concepts

| Concept | Definition |
|:--------|:-----------|
| ğŸ“‹ **Tautology** | Always true (e.g., $P \lor \neg P$) |
| âŒ **Contradiction** | Always false (e.g., $P \land \neg P$) |
| âœ… **Satisfiable** | True under some interpretation |
| ğŸ”„ **Equivalence** | $\alpha \equiv \beta$ if same truth value in all models |
| ğŸ“Š **Entailment** | $KB \vDash \alpha$: $\alpha$ is true in all models where KB is true |

#### ğŸ”¹ Inference Rules

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ğŸ“œ Inference Rules                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  Modus Ponens:          Modus Tollens:                        â”‚
â”‚  Î± â†’ Î², Î±               Î± â†’ Î², Â¬Î²                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”‚
â”‚     Î²                      Â¬Î±                                 â”‚
â”‚                                                               â”‚
â”‚  And-Elimination:       And-Introduction:                     â”‚
â”‚  Î±â‚ âˆ§ Î±â‚‚ âˆ§ ... âˆ§ Î±â‚™     Î±â‚, Î±â‚‚, ..., Î±â‚™                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”‚
â”‚        Î±áµ¢               Î±â‚ âˆ§ Î±â‚‚ âˆ§ ... âˆ§ Î±â‚™                   â”‚
â”‚                                                               â”‚
â”‚  Or-Introduction:       Resolution:                           â”‚
â”‚     Î±áµ¢                  Î± âˆ¨ Î², Â¬Î² âˆ¨ Î³                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€               â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚
â”‚  Î±â‚ âˆ¨ ... âˆ¨ Î±â‚™              Î± âˆ¨ Î³                             â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ğŸ”¹ Resolution Algorithm

> ğŸ’¡ **Resolution** is a complete inference algorithm for propositional logic.

**Steps**:
1. Convert all sentences to **Conjunctive Normal Form (CNF)**
2. Apply resolution rule repeatedly
3. If empty clause derived â†’ contradiction found

**CNF Conversion** ğŸ”„:
- Eliminate â†” (biconditional)
- Eliminate â†’ (implication)
- Move Â¬ inward (De Morgan's laws)
- Distribute âˆ¨ over âˆ§

---

### ğŸ¯ First-Order Logic / Predicate Logic (è°“è¯é€»è¾‘)

> ğŸ’¡ **First-Order Logic (FOL)** extends propositional logic with objects, relations, and quantifiers.

#### ğŸ”¹ Components

| Component | Description | Example |
|:----------|:------------|:--------|
| ğŸ”¹ **Constants** | Specific objects | John, 3, Red |
| ğŸ“¦ **Variables** | Range over objects | x, y, z |
| ğŸ”— **Predicates** | Relations/properties | Brother(x,y), Prime(x) |
| âš¡ **Functions** | Map objects to objects | Father(John), Plus(x,y) |
| ğŸ”— **Connectives** | Same as propositional | âˆ§, âˆ¨, Â¬, â†’, â†” |
| ğŸ“Š **Quantifiers** | Universal / Existential | âˆ€, âˆƒ |

#### ğŸ”¹ Quantifiers

| Quantifier | Meaning | Example |
|:----------:|:--------|:--------|
| **âˆ€** (Universal) | "For all" | âˆ€x Cat(x) â†’ Mammal(x) |
| **âˆƒ** (Existential) | "There exists" | âˆƒx Student(x) âˆ§ Brilliant(x) |

**Quantifier Equivalences** ğŸ”„:
- $\forall x \, P(x) \equiv \neg \exists x \, \neg P(x)$
- $\exists x \, P(x) \equiv \neg \forall x \, \neg P(x)$
- $\forall x \, P(x) \land Q(x) \equiv (\forall x \, P(x)) \land (\forall x \, Q(x))$

#### ğŸ”¹ Knowledge Engineering in FOL

1. **Identify tasks**: What questions should be answerable?
2. **Gather knowledge**: Collect relevant domain facts
3. **Define vocabulary**: Constants, functions, predicates
4. **Encode general rules**: General domain knowledge
5. **Encode specific facts**: Particular problem instance

---

### ğŸ”„ Forward & Backward Chaining

> ğŸ’¡ For **Horn clauses** (disjunctions with at most one positive literal), efficient inference is possible.

#### ğŸ”¹ Forward Chaining (Data-Driven)

```python
function FORWARD_CHAINING(KB, query):
    count â† table of Horn clause premises
    inferred â† table of symbols (all false initially)
    agenda â† queue of known true symbols
    
    while agenda is not empty:
        p â† POP(agenda)
        if p == query then return true
        if inferred[p] == false:
            inferred[p] â† true
            for each Horn clause c where p is in premise:
                decrement count[c]
                if count[c] == 0:
                    add head(c) to agenda
    return false
```

- âœ… **Complete** and **sound**
- â±ï¸ **Linear time**: $O(|KB|)$
- ğŸ“Š May derive many irrelevant facts

#### ğŸ”¹ Backward Chaining (Goal-Driven)

> ğŸ’¡ Works backward from query to known facts.

- âœ… **Complete** and **sound**
- ğŸ’¾ **Linear space**: depth of proof tree
- ğŸ¯ Focuses only on relevant facts
- âš ï¸ May enter infinite loops (need cycle checking)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Forward vs Backward Chaining                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  Forward:                    Backward:                     â”‚
â”‚                                                            â”‚
â”‚      Facts â”€â”€â–º Goals            Goals â”€â”€â–º Facts            â”‚
â”‚                                                            â”‚
â”‚  ğŸŒŠ Data-driven              ğŸ¯ Goal-driven                â”‚
â”‚  ğŸ“ˆ Bottom-up                ğŸ“‰ Top-down                   â”‚
â”‚  ğŸ’¡ Good for monitoring      ğŸ’¡ Good for diagnosis         â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ“Š Summary: Logic Systems

| Feature | Propositional | First-Order |
|:--------|:-------------|:------------|
| **Objects** | âŒ No | âœ… Yes (constants, variables) |
| **Relations** | âŒ No | âœ… Yes (predicates) |
| **Functions** | âŒ No | âœ… Yes |
| **Quantifiers** | âŒ No | âœ… Yes (âˆ€, âˆƒ) |
| **Expressiveness** | Limited | High |
| **Decidability** | Decidable | Semi-decidable |
| **Complexity** | NP-complete | Undecidable |

---

## ğŸ§  Machine Learning

> ğŸ“Œ **Machine Learning** enables systems to **learn from data** and improve performance without explicit programming.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ¯ ML Paradigm                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   ğŸ“Š Training Data â”€â”€â–º ğŸ§  Learning Algorithm â”€â”€â–º ğŸ“¦ Model      â”‚
â”‚        (Examples)          (Induction)           (Hypothesis)   â”‚
â”‚                                                                 â”‚
â”‚   ğŸ“¦ Model â”€â”€â–º ğŸ”® Prediction on New Data                        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ“š Learning Types

| Type | Description | Goal | Examples |
|:-----|:------------|:-----|:---------|
| ğŸ‘¨â€ğŸ« **Supervised** | Labeled data | Learn mapping Xâ†’Y | Classification, Regression |
| ğŸ” **Unsupervised** | Unlabeled data | Discover patterns | Clustering, Dimensionality reduction |
| ğŸ® **Reinforcement** | Trial & error | Maximize reward | Game playing, Robotics |
| ğŸ“ **Semi-supervised** | Mix of labeled/unlabeled | Use unlabeled to help | When labeling is expensive |

---

### ğŸ“ˆ Regression Analysis

> ğŸ’¡ **Regression** predicts continuous values.

#### ğŸ”¹ Linear Regression

> ğŸ“ Models relationship as linear function.

**Hypothesis**: $h_\theta(x) = \theta_0 + \theta_1 x_1 + ... + \theta_n x_n = \theta^T x$

**Cost Function** (MSE): $J(\theta) = \frac{1}{2m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})^2$

**Gradient Descent** ğŸ”„:
```python
repeat until convergence:
    Î¸_j := Î¸_j - Î± âˆ‚J(Î¸)/âˆ‚Î¸_j
    # where âˆ‚J/âˆ‚Î¸_j = (1/m) Î£(h_Î¸(xâ±) - yâ±)x_jâ±
```

| Method | Pros | Cons |
|:-------|:-----|:-----|
| **Gradient Descent** | Scales to large data | Needs learning rate tuning |
| **Normal Equation** | No iteration needed | Slow for large n ($O(n^3)$) |
| **Stochastic GD** | Fast per iteration | Noisy convergence |

#### ğŸ”¹ Logistic Regression

> ğŸ“ For **binary classification** despite the name "regression".

**Sigmoid Function**: $\sigma(z) = \frac{1}{1 + e^{-z}}$

**Hypothesis**: $h_\theta(x) = \sigma(\theta^T x) = P(y=1|x;\theta)$

**Cost Function** (Log Loss):
$J(\theta) = -\frac{1}{m} \sum_{i=1}^{m} [y^{(i)} \log(h_\theta(x^{(i)})) + (1-y^{(i)}) \log(1-h_\theta(x^{(i)}))]$

**Decision Boundary**: Predict $y=1$ if $h_\theta(x) \geq 0.5$

---

### ğŸ§© Perceptron & Neural Networks

#### ğŸ”¹ Perceptron (æ„ŸçŸ¥æœº)

```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Perceptron Architecture        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                       â”‚
â”‚   xâ‚ â”€â”€â–º [wâ‚] â”€â”€â”                     â”‚
â”‚   xâ‚‚ â”€â”€â–º [wâ‚‚] â”€â”€â”¼â”€â”€â–º Î£ â”€â”€â–º Ïƒ â”€â”€â–º y   â”‚
â”‚   xâ‚ƒ â”€â”€â–º [wâ‚ƒ] â”€â”€â”˜    â”‚                â”‚
â”‚                      â–¼                â”‚
â”‚                    [b] bias           â”‚
â”‚                                       â”‚
â”‚   y = Ïƒ(wâ‚xâ‚ + wâ‚‚xâ‚‚ + wâ‚ƒxâ‚ƒ + b)      â”‚
â”‚                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Activation Functions** âš¡:

| Function | Formula | Range | Properties |
|:---------|:--------|:------|:-----------|
| **Sigmoid** | $\frac{1}{1+e^{-x}}$ | (0,1) | Smooth, but vanishing gradient |
| **Tanh** | $\frac{e^x - e^{-x}}{e^x + e^{-x}}$ | (-1,1) | Zero-centered, still vanishing |
| **ReLU** | $\max(0, x)$ | [0,âˆ) | Fast, but "dying ReLU" problem |
| **Leaky ReLU** | $\max(\alpha x, x)$ | (-âˆ,âˆ) | Solves dying ReLU |

#### ğŸ”¹ Multi-Layer Neural Networks

> ğŸ’¡ **Deep Learning**: Networks with multiple hidden layers.

```
Input Layer    Hidden Layer 1    Hidden Layer 2    Output Layer
     â”‚               â”‚                 â”‚               â”‚
   [xâ‚] â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º [hâ‚] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º [hâ‚'] â”€â”€â”€â”€â”€â”€â”€â”€â–º [y]
   [xâ‚‚] â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º [hâ‚‚] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º [hâ‚‚'] â”€â”€â”€â”€â”€â”€â”€â”€â–º
   [xâ‚ƒ] â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º [hâ‚ƒ] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º [hâ‚ƒ'] â”€â”€â”€â”€â”€â”€â”€â”€â–º
   [...]         [...]            [...]
   
   Forward:  zË¡ = WË¡aË¡â»Â¹ + bË¡    aË¡ = Ïƒ(zË¡)
   Backward: âˆ‚J/âˆ‚WË¡ = âˆ‚J/âˆ‚zË¡ Â· âˆ‚zË¡/âˆ‚WË¡
```

**Backpropagation Algorithm** ğŸ”„:
1. Forward pass: Compute predictions
2. Compute loss
3. Backward pass: Compute gradients
4. Update weights using gradient descent

---

### ğŸŒ³ Decision Trees & Random Forest

#### ğŸ”¹ Decision Trees

> ğŸ’¡ Split data based on feature values to maximize information gain.

**Entropy**: $H(S) = -\sum_{i} p_i \log_2(p_i)$

**Information Gain**: $IG(S, A) = H(S) - \sum_{v \in Values(A)} \frac{|S_v|}{|S|} H(S_v)$

```
                    [Outlook?]
                   /    â”‚    \
                Sunny  Rain  Overcast
                 â”‚      â”‚       â”‚
              [Humidity?] [Wind?]  [Play]
              /      \   /    \
           High     Normal Strong Weak
            â”‚         â”‚     â”‚     â”‚
          [No]      [Yes] [No] [Yes]
```

| Algorithm | Split Criterion | Handling |
|:----------|:----------------|:---------|
| **ID3** | Information Gain | Categorical only |
| **C4.5** | Gain Ratio | Categorical + Numeric |
| **CART** | Gini Index | Binary trees |

#### ğŸ”¹ Ensemble Methods

> ğŸ’¡ Combine multiple weak learners to create a strong learner.

**Bagging (Bootstrap Aggregating)** ğŸ’:
- Train multiple models on bootstrap samples
- Average predictions (regression) or vote (classification)
- Reduces variance

**Random Forest** ğŸŒ²ğŸŒ²ğŸŒ²:
- Bagging + random feature subsets
- Highly parallelizable
- Robust to overfitting

**Boosting** ğŸ“ˆ:
- Train models sequentially, focusing on errors
- AdaBoost, Gradient Boosting, XGBoost
- Reduces bias

---

### ğŸ² Naive Bayes

> ğŸ’¡ Probabilistic classifier based on Bayes' theorem with "naive" independence assumption.

**Bayes' Theorem**: $P(Y|X) = \frac{P(X|Y)P(Y)}{P(X)}$

**Naive Assumption**: Features are conditionally independent given the class.

$$P(Y|X_1, ..., X_n) = \frac{P(Y) \prod_{i=1}^{n} P(X_i|Y)}{P(X_1, ..., X_n)}$$

**Types**:
| Variant | Use Case | Distribution |
|:--------|:---------|:-------------|
| **Gaussian NB** | Continuous features | Normal distribution |
| **Multinomial NB** | Text classification | Word counts |
| **Bernoulli NB** | Binary features | Binary distribution |

---

### ğŸ” Unsupervised Learning

#### ğŸ”¹ K-Means Clustering

> ğŸ’¡ Partition data into $k$ clusters by minimizing within-cluster sum of squares.

```python
function K_MEANS(Dataset X, int k):
    Initialize k centroids Î¼â‚, ..., Î¼â‚– randomly
    repeat until convergence:
        # Assignment step
        for each xáµ¢ in X:
            cáµ¢ â† argminâ±¼ ||xáµ¢ - Î¼â±¼||Â²
        
        # Update step
        for j = 1 to k:
            Î¼â±¼ â† mean of all xáµ¢ where cáµ¢ = j
    return centroids Î¼ and assignments c
```

**Properties**:
- â±ï¸ Complexity: $O(n \cdot k \cdot d \cdot i)$ where $i$ = iterations
- âš ï¸ Sensitive to initialization and outliers
- ğŸ“Š Requires choosing $k$ beforehand

#### ğŸ”¹ Hierarchical Clustering

| Type | Description |
|:-----|:------------|
| **Agglomerative** (Bottom-up) | Start with singletons, merge iteratively |
| **Divisive** (Top-down) | Start with all data, split recursively |

**Linkage Criteria** ğŸ”—:
- Single linkage: min distance between clusters
- Complete linkage: max distance between clusters
- Average linkage: avg distance between clusters
- Ward's method: minimize variance

#### ğŸ”¹ Dimensionality Reduction

> ğŸ’¡ Reduce number of features while preserving information.

**PCA (Principal Component Analysis)** ğŸ“Š:
1. Standardize data
2. Compute covariance matrix
3. Find eigenvectors/eigenvalues
4. Select top $k$ eigenvectors
5. Project data onto new basis

---

### ğŸ® Reinforcement Learning (RL)

> ğŸ’¡ Agent learns to make decisions by performing actions in an environment to maximize cumulative reward.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ğŸ® Reinforcement Learning Loop                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           Reward R            â”Œâ”€â”€â”€â”€â”€â”€â”    â”‚
â”‚         â”‚          â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”‚    â”‚
â”‚         â”‚  Agent   â”‚                               â”‚ Env  â”‚    â”‚
â”‚         â”‚          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚      â”‚    â”‚
â”‚         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜           Action A            â””â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚              â”‚                                    â–²            â”‚
â”‚              â”‚                                    â”‚            â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ State S â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ğŸ”¹ Key Components

| Component | Symbol | Description |
|:----------|:-------|:------------|
| **State** | $s$ | Environment configuration |
| **Action** | $a$ | What agent can do |
| **Reward** | $r$ | Immediate feedback |
| **Policy** | $\pi(s)$ | Strategy: which action to take |
| **Value** | $V(s)$ | Expected cumulative reward from $s$ |
| **Q-Value** | $Q(s,a)$ | Expected reward for taking $a$ in $s$ |

#### ğŸ”¹ Q-Learning

> ğŸ’¡ Model-free RL algorithm to learn optimal action-value function.

**Bellman Equation**: $Q(s,a) = r + \gamma \max_{a'} Q(s', a')$

**Update Rule**:
$$Q(s,a) \leftarrow Q(s,a) + \alpha [r + \gamma \max_{a'} Q(s', a') - Q(s,a)]$$

Where:
- $\alpha$ = learning rate
- $\gamma$ = discount factor

**Exploration vs Exploitation** ğŸ¯:
- $\epsilon$-greedy: With prob $\epsilon$, random action; else best action
- Decaying $\epsilon$: Start exploring, gradually exploit

---

### ğŸ—£ï¸ Natural Language Processing (NLP)

> ğŸ’¡ Enable computers to understand, interpret, and generate human language.

#### ğŸ”¹ Text Preprocessing

| Step | Description | Example |
|:-----|:------------|:--------|
| **Tokenization** | Split into words/tokens | "Hello world" â†’ ["Hello", "world"] |
| **Normalization** | Lowercase, remove punctuation | "Hello!" â†’ "hello" |
| **Stopword Removal** | Remove common words | Remove "the", "is", "at" |
| **Stemming/Lemmatization** | Reduce to root form | "running", "ran" â†’ "run" |

#### ğŸ”¹ Text Representations

| Method | Description | Pros/Cons |
|:-------|:------------|:----------|
| **Bag of Words** | Word frequency vectors | Simple, loses word order |
| **TF-IDF** | Weight by inverse document frequency | Reduces common word impact |
| **Word Embeddings** | Dense vectors (Word2Vec, GloVe) | Captures semantic meaning |
| **Transformer** | Contextual embeddings (BERT) | State-of-the-art, expensive |

#### ğŸ”¹ NLP Tasks

- ğŸ“ **Text Classification**: Sentiment analysis, spam detection
- ğŸ·ï¸ **Named Entity Recognition (NER)**: Identify entities (person, org, location)
- ğŸ”— **Part-of-Speech Tagging**: Label word types (noun, verb, etc.)
- ğŸ”„ **Machine Translation**: Translate between languages
- â“ **Question Answering**: Answer questions from text
- ğŸ“ **Text Summarization**: Generate concise summaries

---

### ğŸ“Š ML Model Evaluation

#### ğŸ”¹ Metrics for Classification

| Metric | Formula | Use Case |
|:-------|:--------|:---------|
| **Accuracy** | $(TP + TN) / (TP + TN + FP + FN)$ | Balanced classes |
| **Precision** | $TP / (TP + FP)$ | Minimize false positives |
| **Recall** | $TP / (TP + FN)$ | Minimize false negatives |
| **F1-Score** | $2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}$ | Balance precision/recall |
| **AUC-ROC** | Area under ROC curve | Threshold-independent |

```
                Predicted
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”
         Yes  â”‚  TP   â”‚  FN   â”‚   â† Actual Positive
Actual        â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
         No   â”‚  FP   â”‚  TN   â”‚   â† Actual Negative
              â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†‘         â†‘
            Predicted   Predicted
            Positive    Negative
```

#### ğŸ”¹ Bias-Variance Tradeoff

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ğŸ“Š Bias-Variance Tradeoff                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   High Bias (Underfitting)      High Variance (Overfitting) â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”                      â”Œâ”€â” â”Œâ”€â” â”Œâ”€â”             â”‚
â”‚       /       \                   /   X   X   \            â”‚
â”‚      /         \                /  X     X     X           â”‚
â”‚     /           \             X    X   X   X    X          â”‚
â”‚    /             \          X  X   X       X  X  X         â”‚
â”‚                                                             â”‚
â”‚   Too simple                     Too complex                â”‚
â”‚   Miss patterns                  Fits noise                 â”‚
â”‚                                                             â”‚
â”‚   Solution:                      Solution:                  â”‚
â”‚   â€¢ More features                â€¢ More data                â”‚
â”‚   â€¢ More complex model           â€¢ Regularization           â”‚
â”‚   â€¢ Reduce regularization        â€¢ Simpler model            â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Regularization Techniques** ğŸ”§:
- **L1 (Lasso)**: $\lambda \sum |w_i|$ â†’ Sparse weights, feature selection
- **L2 (Ridge)**: $\lambda \sum w_i^2$ â†’ Small weights, no sparsity
- **Dropout**: Randomly drop neurons during training
- **Early Stopping**: Stop when validation error increases

---

### ğŸ¯ Summary: ML Algorithms

| Task | Algorithms | Key Considerations |
|:-----|:-----------|:-------------------|
| **Regression** | Linear, Polynomial, SVR | Feature scaling, non-linearity |
| **Classification** | Logistic Regression, SVM, k-NN, Trees | Class imbalance, decision boundary |
| **Neural Nets** | MLP, CNN, RNN, Transformers | Architecture, hyperparameters |
| **Clustering** | k-Means, DBSCAN, Hierarchical | Choosing k, density assumptions |
| **Dimensionality** | PCA, t-SNE, Autoencoders | Information loss, visualization |
| **RL** | Q-Learning, Policy Gradient, Actor-Critic | Exploration, reward design |

---

> ğŸ“š **End of Notes** | ğŸ“ Artificial Intelligence Course Material | ğŸ† Happy Learning!